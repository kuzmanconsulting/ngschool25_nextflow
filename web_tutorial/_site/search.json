[
  {
    "objectID": "1_intro.html",
    "href": "1_intro.html",
    "title": "Introduction",
    "section": "",
    "text": "Tip\n\n\n\nThere is a great community around nextflow, and tons of training material exist for all levels of experience with it. This workshop is heavily based on materials provided in those courses, assembled to my personal preferences. I sincerely encourage you to learn nextflow on your own using the materials available on the official nextflow training website.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "1_intro.html#this-is-intro-slide",
    "href": "1_intro.html#this-is-intro-slide",
    "title": "Introduction",
    "section": "",
    "text": "Something is written here. Nice!",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "1_intro.html#processes-and-channels.",
    "href": "1_intro.html#processes-and-channels.",
    "title": "Introduction",
    "section": "",
    "text": "In practice, a Nextflow workflow is made by joining together different processes. Each process can be written in any scripting language that can be executed by the Linux platform (Bash, Perl, Ruby, Python, etc.).\nProcesses are executed independently and are isolated from each other, i.e., they do not share a common (writable) state. The only way they can communicate is via asynchronous first-in, first-out (FIFO) queues, called channels. In other words, every input and output of a process is represented as a channel. The interaction between these processes, and ultimately the workflow execution flow itself, is implicitly defined by these input and output declarations.\n#!/usr/bin/env nextflow\n\nparams.greeting = 'Hello world!' #| This sets a greeting message\ngreeting_ch = Channel.of(params.greeting) #| Creates a Nextflow channel from the greeting\n\nprocess SPLITLETTERS {\n    input:\n    val x #| Takes a single input value\n\n    script:\n    \"\"\"\n    echo $x | fold -w1\n    \"\"\"\n}",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "1_intro.html#processes-and-channels",
    "href": "1_intro.html#processes-and-channels",
    "title": "Introduction",
    "section": "Processes and Channels",
    "text": "Processes and Channels\nNextflow workflow is made by joining together different processes. Each process can be written in any scripting language that can be executed by the Linux platform (Bash, Perl, Ruby, Python, etc.).\n\nProcesses are executed independently and are isolated from each other. The only way they can communicate is via ‚Äúchannels‚Äù, asynchronous first-in, first-out (FIFO) queues. In other words, every input and output of a process is represented as a channel. The interaction between these processes, and ultimately the workflow execution flow itself, is implicitly defined by these input and output declarations.\n\n#!/usr/bin/env nextflow\n\nparams.greeting = 'Hello world!' #| This sets a greeting message\ngreeting_ch = Channel.of(params.greeting) #| Creates a Nextflow channel from the greeting\n\nprocess SPLITLETTERS {\n    input:\n    val x #| Takes a single input value\n\n    script:\n    \"\"\"\n    echo $x | fold -w1\n    \"\"\"\n}",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "1_intro.html#my-first-nextflow-script",
    "href": "1_intro.html#my-first-nextflow-script",
    "title": "Introduction",
    "section": "My first nextflow script",
    "text": "My first nextflow script\n\nnextflow.enable.dsl=2\n\n\nworkflow {\n  \n  // parse input:\n    infile = params.infile\n  infile_channel = Channel.fromList( infile )\n  \n  // run FASTQC:\n  FASTQC(infile_1_channel, infile_2_channel)\n\n}\n\n\nprocess FASTQC {\n    \n    label 'fastqc'\n    \n    input:\n    path infilename\n\n    output:\n    path '*' \n        \n    shell:\n  '''\n  fastqc !{infilename}  \n  '''\n}",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "1_intro.html#nextflow-training-materials",
    "href": "1_intro.html#nextflow-training-materials",
    "title": "Introduction",
    "section": "",
    "text": "Tip\n\n\n\nThere is a great community around nextflow, and tons of training material exist for all levels of experience with it. This workshop is heavily based on materials provided in those courses, assembled to my personal preferences. I sincerely encourage you to learn nextflow on your own using the materials available on the official nextflow training website.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "1_intro.html#learning-objectives",
    "href": "1_intro.html#learning-objectives",
    "title": "Introduction",
    "section": "Learning objectives",
    "text": "Learning objectives\nBy the end of this workshop you should be able to:\n\nWrite a simple Nextflow workflow\nHave basic understanding of the concepts of Channels, Processes and Operators\nRun an test nf-core pipeline\nKnow where to go next ü§∑",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "1_intro.html#learning-objectives-1",
    "href": "1_intro.html#learning-objectives-1",
    "title": "Introduction",
    "section": "Learning objectives¬∂",
    "text": "Learning objectives¬∂\nBy the end of this workshop you should be able to:\n\nWrite a simple Nextflow workflow\nDescribe the Nextflow concepts of Channels, Processes and Operators\nHave an understanding of containerized workflows\nUnderstand the different execution platforms supported by Nextflow\nDescribe the Nextflow community and ecosystem",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "1_intro.html#the-problem",
    "href": "1_intro.html#the-problem",
    "title": "Introduction",
    "section": "The problem",
    "text": "The problem\nLets say we want to do the following, as I am sure you have done many times before:\nWe will start with fastq data and perform trimming, after which we will perform fastqc.\n\n\nSolution - bash\nIn bash we would do this:\nfastp --in1 liver_1.fq \\\n      --in2 liver_2.fq \\\n      --out1 liver_1.trimmed.fq \\\n      --out2 liver_2.trimmed.fq \\\n      -h liver.html \n\nfastqc liver_1.fq\nfastqc liver_1.trimmed.fq\nBut of course, it will fail since we do not have fastp and fastqc installed.\n\n\n\n\n\n\nTip\n\n\n\nGood practice is to use containers which will enable reproducibility. Building dockerfiles and images is sometimes tricky, but also could be defying the purpose of reproducible research. You can find many already available dockers/singularity images at dockerhub and quay.io .\n\n\n\n\nUse containers!\nWe will use the docker for fastp and fastqc available on dockerhub:\nFirst; pull the container locally:\n\ndocker pull biocontainers/fastqc:v0.11.9_cv8\n\nNext, enter the container image:\n\ndocker run -v .:/data -it biocontainers/fastqc:v0.11.9_cv8\n\n\nExplanation\n\nIf we wanted to do this on multiple files we could write a bash script:\n\n\n\n\n\n\ncommand\nexplained\n\n\n\n\ndocker run\nThis is the basic Docker command used to create and start a new container from a specified image.\n\n\n-v .:/data\nThis flag mounts a volume. Here, the current directory (represented by .) on your host machine is mapped to the /data directory inside the container. This means any files in your current directory will be accessible in /data within the container, and changes made there will be reflected back on your host.\n\n\n-i (interactive)\nKeeps STDIN open so you can interact with the container.\n\n\n-t (tty)\nAllocates a pseudo-TTY, which provides a terminal session inside the container.\nTogether, they allow you to run the container in interactive mode, making it easier to execute commands and see outputs.\n\n\nbiocontainers/fastqc:v0.11.9_cv8\nThis is the Docker image being used. It specifies: image and tag.\n\n\n\n\n\n\nLets try to run it on our 4 samples:\n‚Ä¶",
    "crumbs": [
      "Introduction"
    ]
  }
]