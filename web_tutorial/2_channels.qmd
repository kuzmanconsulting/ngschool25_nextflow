---
title: "Nextflow intro"  
---

# Solution - nextflow style

Nextflow takes care of all of those problems for us. It is both an workflow orchestrator and a coding language.

::: {.callout-note appearance="simple"}
## key terms

**workflow**: pipeline in nextflow is called a workflow

**channel**: structure which transfers data between steps in the pipeline

**process**: task that will happen on data
:::

## Processes and Channels

Nextflow workflow is made by joining together different processes. Each process can be written in any scripting language that can be executed by the Linux platform (Bash, Perl, Ruby, Python, etc.).

![](images/clipboard-1373747047.png)

Processes are executed independently and are isolated from each other. The only way they can communicate is via "channels", asynchronous first-in, first-out (FIFO) queues. In other words, every input and output of a process is represented as a channel. The interaction between these processes, and ultimately the workflow execution flow itself, is implicitly defined by these input and output declarations.

## My first nextflow script

First nextflow script : code/my_first_script.nf 

```{r}
cd web_tutorial
mkdir tests
cd tests

nextflow run ../code/my_first_script.nf 
```

::: {.callout-note appearance="minimal"}
### Explanation:

**`nextflow run code/my_first_script.nf`** runs a nextflow script code/my_first_script.nf\
Parameters which are nextflow-related are handed with a single dash.
:::

## Script walkthrough

```{nextflow}
nextflow.enable.dsl=2 # (Domain-Specific Language version 2)

process FASTQC {
    
  container 'biocontainers/fastqc:v0.11.9_cv8'

  input:
  path infilename

  output:
  path '*' 
      
  script:
  """
  fastqc ${infilename}  
  """
}

workflow {

  // parse input:
  infile_channel = Channel.fromPath( "../../data/liver_1.fq" )

  // run FASTQC:
  FASTQC(infile_channel)

}

```


## script1.nf

To view a content of a channel, you can use the operator view() For example, we created code/script1.nf where we only created a channel from a file. To view it, just add .view() after a channel.

```{nextflow}
# code/script1.nf
workflow {

  // parse input:
  infile_channel_1 = 
    Channel.fromPath( "../../data/liver_*.fq" )
    .view()

}

```

We did this in [script1](code/script1.nf) . So lets run it and see what we get:

```{r}
nextflow run ../code/script1.nf 
```


### Note on channels

There are two types of channels in nextflow:

**queue channels** and **value channels. Queue channels** are expendable, they can only be used once - like when you pipe data in bash. Once used, elements in this queue cannot be re-used. Most channels in nextflow are queue channels. Value channels are long-lived and can be re-used, but they always only hold a single value. They usually hold constant values (or absolute paths).

There are many ways to create a channel in nextflow, I advise you to look at [the official documentation on channel factories](https://www.nextflow.io/docs/latest/reference/channel.html#channel-factory) for more information.


::: callout-exercise
Results are saved in working directory, two layers down. There, .html and .zip files are created.

## ðŸ’¡ Exercise: task2

1.  change script2.nf to: write `liver_*.fq` instead of `liver_1.fq` and view the infile_channel.
2.  when process is ran, the outputs are also gathered into a channel. In other words, FASTQC(infile_channel) is also a channel. View the elements in it!
:::

```{bash, eval=FALSE, task2}
# change ../code/script2.nf and run it.
# 1. change liver_1.fq to *fq 
# add .view() to view output of the input channel!

# run the script:  
nextflow run ../code/script2.nf  

# view the outfile channel and run the script again


```



:::: callout-warning
## ðŸ’¡ Solution:

```{bash, eval=FALSE, solution-task2}
#| code-fold: true

workflow {

  // parse input:
  infile_channel = Channel.fromPath( "../../data/liver_*.fq" )
                      .view()
  // run FASTQC:
  FASTQC(infile_channel)
    .view()

}

nextflow run ../code/script2.nf  

```

::: callout-tip
If you add -ansi-log false to nextflow run command, you will see all the processes instead of single process per line!

``` bash
nextflow run ../code/script2.nf  -ansi-log false
```

Now fastqc is ran 2 times!
:::
::::

### publishDir

Now we created multiple files as results, but they are all somewhere around in the work directory. You can define publishDir to have the resuls all in one place.

Add the following line to the process:

```{bash}
#process:
  publishDir "results"

#run in bash: 
nextflow run ../code/script2.nf  
```

Now the results (liver_1_fastqc.html liver_1_fastqc.zip liver_2_fastqc.html liver_2_fastqc.zip) will be saved in the folder: `results/` liver_1_fastqc.html liver_1_fastqc.zip liver_2_fastqc.html liver_2_fastqc.zip

### output channels

If you want to collect only html files, you can specify this in the output by :

```{bash}
#process: 
  output:
  path "*html"
 
# bash:
#remove the results folder and run the script again:  
rm -rf results
nextflow run ../code/script2.nf  
```

Now the fastqc process only outputs the html files in the channel, and only they are in the results folder.

We have seen already that output is a channel. If we want to direct different outputs into different channels, this can be easily done by specifying where the output will be directed to - using the **emit** keyword.


```{bash}
#in process:  

  output :
  path "*html"
  path "*zip", emit: zip

```

::: {.callout-warning}
This will produce an error:  
```{bash}

# in workflow: 
  FASTQC(infile_channel).view()

# in bash:
# remove the results folder and run again:
rm -rf results
nextflow run ../code/script2.nf  
```

Output produces 2 channels, and nextflow doesnt know which one we want. You should specify which one you are interestred in by choosing .html or .zip. 
So, do this:  

```{bash}

# in workflow: 
  FASTQC(infile_channel).zip.view()

# in bash:
# remove the results folder and run again:
rm -rf results
nextflow run ../code/script2.nf  
```


:::

:::::: {.callout-note}
## output VS emit  

1. **output:**  Note - when you specify output, all the files which are there are expected to exist and are going to be in the final result folder. If some file is not produced, nextflow will give an error. This can be circumvented by using the argumant optional: true.  

2. **emit: name** - emit will direct those outputs into a channel named PROCESS.name .  

:::


::: callout-note
Note that in a similar way in which channels are expendable, so are processes. If you use a process once, it is no longer usable later. Each time you call a process, you use it. So if you want to save an output of a process to two different channels, save it to a channel, then access the different channels within it by calling the emit name (eg `out_channel.html` and `out_channel.zip` )
:::



```{bash}

# in workflow: 
  out_channel = FASTQC(infile_channel)
  println ("out_html: ") 
  out_channel.html.view()
 // println ("out_zip: ") 
 // out_channel.zip.view()

# in bash:
# remove the results folder and run again:
rm -rf results
nextflow run ../code/script2.nf  
```
  

### -resume.

We have now repeated the fastqc computation a lot of times already. There is a neat option in nextflow which allowes you to save computation time and repeat only the steps which have changed. you can activate it by running nextflow command with -resume tag.

```{bash}

nextflow run ../code/script2.nf  -resume
```

This way only the steps we change will be ran again, the rest will be found in cache!!

... So far so good?

### params.

Of course, you don't need to hard code the path, you can use variable that will store a path of the file/files you want to input.

in the workflow, you can simply replace the actual file path with a parameter defined in params.nameoftheparameter, where nameoftheparameter can be any variable name you choose.

```{bash}
# in the workflow:  
#  // parse input:
  infile_channel = Channel.fromPath( params.infile )
                    .view()

```

By using the special word **params**. nextflow will look at the parameters which were provided when the run was executed. Neat thing about this is that you can define the parameter directly when you call the nextflow run:

::: callout-tip
to define a parameter while callling a nextflow run, simply use double dash: '`--`' followed by the name of the parameter.

for example, to specify a `param.infile` in workflow, we would need to call

`nextflow run --infile "path/to/file"` .

Alternatively, you can create a config file and store your parameters there! - neat for keeping track of runs!
:::

\
Try it out!

```{bash}

nextflow run ../code/script2.nf -resume --infile "../../data/*fq"

```

## script3.nf

### fromFilePairs

There are many ways to input a file to channel. In bioinformatics, there is often a need to input pairs of files. So, in nextflow there is a special operator for this **fromFilePairs** .

Lets try this out in script 3: Open and change script3:

```{bash}

# workflow {

  // parse input:
  infile_channel = Channel.fromFilePairs( params.infile )
                    .view()
 

```

and call it with:

```{bash}

nextflow run ../code/script3.nf -resume --infile "../../data/*{1,2}.fq"

```

When using fromFilePairs we need to specify file pairs to input. `*{1,2}.fq` means the input will be all pairs of files ending with _1.fq and _2.fq and everything before that will be considered sample id.

This creates a channel with 3 elements each of which are a tuple of two elements. First one is the sample ID, and second one is a list of two elements, which are paths to file_1.fq and file_2.fq.

It is easy to access the individual elements, you can do it in the following way:

In the process, it is easy to parse this, just instead of `path infilename` use:

```{bash}
tuple val(sampleid),path(infiles)
```

Now we can access individual file from infiles with `${infiles[0]} ${infiles[1]}`, and we know the sampleid, it is saved as variable `${sampleid}`.

Another neat thing you can do is to tag the process execution by some name, lets see this by using "tag":

```{bash}
# process
process FASTQC {
    
  container 'biocontainers/fastqc:v0.11.9_cv8'
  tag "running on $sampleid" 

  input:
  tuple val(sampleid),path(infiles)
  
  output:
  path '*html' 
  publishDir "results"

  
  script:
  """
  fastqc ${infiles[0]} ${infiles[1]}
  """
}


# workflow, add:
FASTQC(infile_channel)
      .view()

# run with: 
nextflow run ../code/script3.nf --infile "../../data/*{1,2}.fq" -ansi-log false

```

# Try it out!  
## script4.nf

OK, cool! We are ready for some exercise!!


::: callout-exercise
## ðŸ’¡ Exercise: Add outdir parameter!

Add a parameter "outdir" to specify where the output location is for the final nextflow results.
:::

::: callout-warning
## ðŸ’¡ Solution: Add a parameter !

Adding the parameter to script:

```{bash, eval=FALSE, solution-task3a}
#| code-fold: true

process FASTQC {
    
  container 'biocontainers/fastqc:v0.11.9_cv8'
  tag "$sampleid"

  input:
  tuple val(sampleid),path(infiles)
  
  output:
  path '*html' 
  publishDir params.outdir

  
  script:
  """
  fastqc ${infiles[0]} ${infiles[1]} 
  """
}
```

Running it with outdir:

```{bash, eval=FALSE, solution-task3b}
#| code-fold: true

nextflow run ../code/script3.nf  -c ../code/config.nf -resume --infile "../../data/*{1,2}.fq" --outdir tryme 

```
:::





::: callout-exercise
## ðŸ’¡ Exercise: Add a trimming step!

OK, we are ready for a bigger bite!

Create a new process, TRIM that will trim the fastq files BEFORE the FASTQ step, as we did before with bash: Use appropriate variables as needed!

Remember, we used the container: `'biocontainers/fastp:v0.20.1_cv1'`.

This is what we have from before:

```{bash}

fastp\
  --in1 data/liver_1.fq\
  --in2 data/liver_2.fq\
  --out1 data/liver_1.trimmed.fq\
  --out2 data/liver_2.trimmed.fq\
  -h liver.html 

```
:::

::: callout-warning
## ðŸ’¡ Solution: Add a trimming step!

Adding the TRIM process to script:

```{bash, eval=FALSE, solution-task4a}
#| code-fold: true

process TRIM {
    
  container 'biocontainers/fastp:v0.20.1_cv1'
  tag "$sampleid"

  input:
  tuple val(sampleid),path(infiles)
  
  output:
  path '*trimmed.fq', emit: trimmed 

  
  script:
  """
  fastp\
  --in1 ${infiles[0]}\
  --in2 ${infiles[1]}\
  --out1 ${sampleid}_1.trimmed.fq\
  --out2 ${sampleid}_2.trimmed.fq\
  -h ${sampleid}.html 

  """
}

workflow {

  // parse input:
  infile_channel = Channel.fromFilePairs( params.infile )
                    .view()
  // run FASTQC:
  trimmed_channel = TRIM(infile_channel).trimmed
  FASTQC(trimmed_channel) 

}

```

Running it :

```{bash, eval=FALSE, solution-task4b}
#| code-fold: true

nextflow run ../code/script3.nf  -resume --infile "../../data/*{1,2}.fq" --outdir tryme -asi-log false

```
:::

::: callout-exercise
## ðŸ’¡ Exercise: Add a new FASTQC_SINGLE step!

If you want extra work, create additional process, FASTQC_SINGLE. Change the parameters of FASTQC to be able to input and process only a single file. Run that process on the output of TRIM step.
:::

::: callout-warning
## ðŸ’¡ Solution: Add a new FASTQC_SINGLE step!

```{bash, eval=FALSE}
#| code-fold: true

process FASTQC_SINGLE {
    
  container 'biocontainers/fastqc:v0.11.9_cv8'
  tag "$sampleid"

  input:
  path infile
  
  output:
  path '*html' 
  publishDir params.outdir

  
  script:
  """
  fastqc ${infile}
  """
}


workflow {

  // parse input:
  infile_channel = Channel.fromFilePairs( params.infile )
                    .view()
  // run FASTQC:
  FASTQC(infile_channel) 
  trimmed_channel = TRIM(infile_channel)
  FASTQC_SINGLE(trimmed_channel.trimmed) 

}

```

Running it :

```{bash, eval=FALSE, solution-task5b}
#| code-fold: true

nextflow run ../code/script4.nf  -c ../code/config.nf -resume --infile "../../data/*{1,2}.fq" 

```
:::

