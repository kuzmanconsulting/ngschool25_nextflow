---
title: "Nextflow intro"  
---

# Solution - nextflow style

Nextflow takes care of all of those problems for us. It is both an workflow orchestrator and a coding language.

::: {.callout-note appearance="simple"}
## key terms

**workflow**: pipeline in nextflow is called a workflow

**channel**: structure which transfers data between steps in the pipeline

**process**: task that will happen on data
:::

## Processes and Channels

Nextflow workflow is made by joining together different processes. Each process can be written in any scripting language that can be executed by the Linux platform (Bash, Perl, Ruby, Python, etc.).

![](images/clipboard-1373747047.png)

Processes are executed independently and are isolated from each other. The only way they can communicate is via "channels", asynchronous first-in, first-out (FIFO) queues. In other words, every input and output of a process is represented as a channel. The interaction between these processes, and ultimately the workflow execution flow itself, is implicitly defined by these input and output declarations.

## My first nextflow script

[First nextflow script](code/my_first_script.nf)

```{r}
mkdir tests
cd tests

nextflow run ../code/my_first_script.nf 
```

::: {.callout-note appearance="minimal"}
### Explanation:

**`nextflow run code/my_first_script.nf`** runs a nextflow script code/my_first_script.nf\
**`-c config.nf`** uses configuration file for nextflow run. Parameters which are nextflow-related are handed with a single dash.
:::

## Script walkthrough

```{nextflow}
nextflow.enable.dsl=2 # (Domain-Specific Language version 2)

process FASTQC {
    
  container 'biocontainers/fastqc:v0.11.9_cv8'

  input:
  path infilename

  output:
  path '*' 
      
  script:
  """
  fastqc ${infilename}  
  """
}

workflow {

  // parse input:
  infile_channel = Channel.fromPath( "../../data/liver_1.fq" )

  // run FASTQC:
  FASTQC(infile_channel)

}

```


To view a content of a channel, you can use the operator view() For example, we created code/script1.nf where we only created a channel from a file. To view it, just add .view() after a channel.

```{nextflow}
# code/script1.nf
workflow {

  // parse input:
  infile_channel_1 = 
    Channel.fromPath( "../../data/liver_*.fq" )
    .view()

}

```

We did this in [script1](code/script1.nf) . So lets run it and see what we get:

```{r}
nextflow run ../code/script1.nf 
```

::: callout-exercise
## ðŸ’¡ Exercise: task2

What will happen if you try to run the previous my_first_script.nf with "../../data/liver\_\*.fq" instead of "../../data/liver_1.fq" also add infile_channel.view() . Try to run it yourself!
:::

```{bash, eval=FALSE, task2}
cp ../code/my_first_script.nf ../code/script2.nf
# change ../code/script2.nf and run it.
# 1. change liver_1.fq to *fq 
# add .view() to view output of the channel!

nextflow run ../code/script2.nf  

```

::: callout-warning
## ðŸ’¡ Solution:

```{bash, eval=FALSE, solution-task2}
#| code-fold: true


cp ../code/my_first_script.nf ../code/script2.nf
# change ../code/script2.nf and run it.
sed  -i 's|../../data/liver_1.fq" )|../../data/liver_*.fq" ).view()|g' ../code/script2.nf

nextflow run ../code/script2.nf  

```

Note: if you add -ansi-log false to nextflow run command, you will see all the processes instead of single process per line!  

```{bash}
nextflow run ../code/script2.nf  -ansi-log false

```

:::



Now fastqc is ran 2 times!

::: callout-tip
There are many ways to create a channel in nextflow, I advise you to look at [the official documentation on channel factories](https://www.nextflow.io/docs/latest/reference/channel.html#channel-factory) for more information.
:::

### publishDir

Now we created multiple files as results, but they are all somewhere around in the work directory. You can define publishDir to have the resuls all in one place.

Add the following line to the process:

```{bash}
  publishDir "results"

```

If you want to collect only html files, you can specify this in the output by :

```{bash}
  output "*html"

```

Actually, the process call creates a channel of outputs! 

To view the output channel, just call view in it, as a normal channel, like this:  

```{bash}
  FASTQC(infile_channel).view() 
```

### -resume.

We have now repeated the fastqc computation a lot of times already. There is a neat option in nextflow which allowes you to save computation time and repeat only the steps which have changed. you can activate it by running nextflow command with -resume tag.

```{bash}

nextflow run ../code/script2.nf  -resume
```

This way only the steps we change will be ran again, the rest will be found in cache.

### input as a parameter.

Of course, you don't need to hard code the path, you can use variable that will store a path of the file/files you want to input.

in the workflow, you can simply replace the actual file path with a parameter defined in params.nameoftheparameter, where nameoftheparameter can be any variable name you choose.

```{bash}
# in the workflow:  
#  // parse input:
  infile_channel = Channel.fromPath( params.infile )
                    .view()

```

Neat thing about this is that you can define the parameter directly when you call the nextflow run:

::: callout-tip
to define a parameter while callling a nextflow run, simply use double dash: '`--`' followed by the name of the parameter.

for example, to specify a `param.infile` in workflow, we would need to call

`nextflow run --infile "path/to/file"` .

Alternatively, you can create a config file and store your parameters there! - neat for keeping track of runs!

:::

\
Try it out!

```{bash}

nextflow run ../code/script2.nf -resume --infile "../../data/*fq"

```

### fromFilePairs

There are many ways to input a file to channel. In bioinformatics, there is often a need to input pairs of files. So, in nextflow there is a special operator for this **fromFilePairs** .

Lets try this out in script 3:
Open and change script3:

```{bash}

workflow {

  // parse input:
  infile_channel = Channel.fromFilePairs( params.infile )
                    .view()
 
}
```

and call it with:

```{bash}

nextflow run ../code/script3.nf -resume --infile "../../data/*{1,2}.fq"

```

This creates a channel which is a tuple of two elements. First one is the sample ID, and second one is another tuple of two elements, which are paths to file_1.fq and file_2.fq.

It is easy to access the individual elements, you can do it in the following way:

In the process, it is easy to parse this, just instead of `path infilename` use:

```{bash}

tuple val(sampleid),path(infiles)

```

Now we can access individual file from infiles with `${infiles[0]} ${infiles[1]}`, and we know the sampleid, it is saved as variable `${sampleid}`.

Another neat thing you can do is to tag the process execution by some name, lets see this by using "tag":

```{nextflow}
process FASTQC {
    
  container 'biocontainers/fastqc:v0.11.9_cv8'
**  tag "running on $sampleid" **

  input:
  tuple val(sampleid),path(infiles)
  
  output:
  path '*html' 
  publishDir "results"

  
  script:
  """
  fastqc ${infiles[0]} ${infiles[1]}
  """
}

```

OK, cool! We are ready for some exercise!!

::: callout-exercise
## ðŸ’¡ Exercise: Add outdir parameter!

Add a parameter "outdir" to specify where the output location is for the final nextflow results.
:::

::: callout-warning
## ðŸ’¡ Solution: Add a parameter !

Adding the parameter to script:

```{bash, eval=FALSE, solution-task3a}
#| code-fold: true

process FASTQC {
    
  container 'biocontainers/fastqc:v0.11.9_cv8'
  tag "$sampleid"

  input:
  tuple val(sampleid),path(infiles)
  
  output:
  path '*html' 
  publishDir params.outdir

  
  script:
  """
  fastqc ${infiles[0]} ${infiles[1]} 
  """
}
```

Running it with outdir:

```{bash, eval=FALSE, solution-task3b}
#| code-fold: true

nextflow run ../code/script3.nf  -c ../code/config.nf -resume --infile "../../data/*{1,2}.fq" --outdir tryme 

```
:::

::: callout-exercise
## ðŸ’¡ Exercise: Add a trimming step!

OK, we are ready for a bigger bite!

Create a new process, TRIM that will trim the fastq files as we did before: Use appropriate variables as needed!

Remember, we used the container: `'biocontainers/fastp:v0.20.1_cv1'`.

This is what we have from before:

```{bash}

fastp\
  --in1 data/liver_1.fq\
  --in2 data/liver_2.fq\
  --out1 data/liver_1.trimmed.fq\
  --out2 data/liver_2.trimmed.fq\
  -h liver.html 

```
:::

::: callout-warning
## ðŸ’¡ Solution: Add a trimming step!

Adding the TRIM process to script:

```{bash, eval=FALSE, solution-task4a}
#| code-fold: true

process TRIM {
    
  container 'biocontainers/fastp:v0.20.1_cv1'
  tag "$sampleid"

  input:
  tuple val(sampleid),path(infiles)
  
  output:
  path '*' 
  publishDir params.outdir

  
  script:
  """
  fastp\
  --in1 ${infiles[0]}\
  --in2 ${infiles[1]}\
  --out1 ${sampleid}_1.trimmed.fq\
  --out2 ${sampleid}_2.trimmed.fq\
  -h ${sampleid}.html 

  """
}

workflow {

  // parse input:
  infile_channel = Channel.fromFilePairs( params.infile )
                    .view()
  // run FASTQC:
  FASTQC(infile_channel) 
  trimmed_channel = TRIM(infile_channel).out
  FASTQC(trimmed_channel) 

}

```

Running it :

```{bash, eval=FALSE, solution-task4b}
#| code-fold: true

nextflow run ../code/script3.nf  -c ../code/config.nf -resume --infile "../../data/*{1,2}.fq" --outdir tryme 

```
:::

::: callout-exercise
## ðŸ’¡ Exercise: Add a new FASTQC_SINGLE step!

If you want extra work, create additional process, FASTQC_SINGLE. Change pthe parameters of FASTQC to be able to input and process only a single file. Run that process on the output of TRIM step.
:::

::: callout-warning
## ðŸ’¡ Solution: Add a new FASTQC_SINGLE step!

```{bash, eval=FALSE}
#| code-fold: true

process FASTQC_SINGLE {
    
  container 'biocontainers/fastqc:v0.11.9_cv8'
  tag "$sampleid"

  input:
  path infile
  
  output:
  path '*html' 
  publishDir params.outdir

  
  script:
  """
  fastqc ${infile}
  """
}


workflow {

  // parse input:
  infile_channel = Channel.fromFilePairs( params.infile )
                    .view()
  // run FASTQC:
  FASTQC(infile_channel) 
  trimmed_channel = TRIM(infile_channel)
  FASTQC_SINGLE(trimmed_channel.trimmed) 

}

```

Running it :

```{bash, eval=FALSE, solution-task5b}
#| code-fold: true

nextflow run ../code/script3.nf  -c ../code/config.nf -resume --infile "../../data/*{1,2}.fq" --outdir tryme 

```
:::

## Logging

Want to see something quite cool?

Every nextflow run automatically loggs all of its progress. The main log from, the last run is always saved as .nextflow.log. Check it out!

```{bash}
cat .nextflow.log  

```

There are many information, most useful might be seeing per process status: 

```{bash}
cat .nextflow.log | grep COMPLETED  

```

Whatever is completed successfully has the exit status 0. So if you grep everything which does not have exit status 0 you will find all failed processes: 

```{bash}
 cat .nextflow.log | grep COMPLETED | grep -v "exit: 0"
```


Just adding flags -with-report -with-dag -with-timeline -with-trace enable reporrts on the pipeline generated automatically.

If you also want to see all the processes being ran, you can add -ansi-log false

```{bash}
run ../code/script3.nf  -c ../code/config.nf -resume --infile "../../data/*{1,2}.fq" --outdir tryme -with-report -with-dag -with-timeline -with-trace -ansi-log false
```


### Timeline

![](images/paste-1.png)

### DAG

![](images/paste-2.png){width="271"}

Nextflow automatically draws a graph of the workflow!

### Report

Nextflow tracks all progress for each run! You can easily get information on how much CPUs or memory was actually used in a process, and get a lot of additional details on where the processes were run.

#### Process work dir

Every process working directory is available. Check one in the report and enter it. In there, you have :

::: {.callout-note appearance="simple"}
## Important files

**.command.run**: File that sets the stage. It configures the containers and prepares the environment to run the process.

**.command.sh**: The actual script being run. If you need to change something, best way is to change the .sh and run with .command.run

**.command.err**: Errors outputted by the process.

**.command.log**: Log outputted by the process.

**.command.out**: Any standard output outputted by the process.

**.exitcode**: If 0, everything is ok.
:::

::: callout-exercise
## ðŸ’¡ Exercise: Fix a broken pipeline! ðŸ’”

( This might be the most useful exercise of all.. )
:::

::: callout-exercise
Run the following code and fix it .

```{bash}

nextflow run ../code/script4.nf  -c ../code/config.nf -resume --infile "../../data/*{1,2}.fq" --outdir tryme -with-report -with-dag -with-timeline -with-trace
```


:::


::: callout-warning
## ðŸ’¡ Solution: Fix the pipeline!  
```{bash}
#| code-fold: true

#If you run 

cat .nextflow.log | grep COMPLETED | grep -v "exit: 0"

#Or check the execution report, you will find which working directory was problematic.  
#In there, you can check out .command.err and see that fastp command wasnt found. 
# We were supposed to do fastqc in this step, so no wonder. 
# change the fastp to fastqc in the .command.sh, and run the .command.run to verify the problem is solved.

sed -i "" "s|fastp|fastqc|g" .command.sh
# change permission to be able to run .command.run

chmod +x .command.run
./.command.run

#Works! 

#now change in the original pipeline and run with -resume!

```



:::



::: {.callout-tip}
## Getting tricky    
In the same way that input can be tuple, also we can output (emit a channel) that is made of tuples !  

So, lets try it!  
Add the following to the script and view the outputed channel!  

```{bash}

  tuple val(sampleid), path('*trimmed.fq'), emit: tup, optional: true

```

Lets use it to create and run a new process which will do the mapping to the transcriptome!  

( Because we can! ) For example, use the container `biocontainers/bwa:v0.7.17_cv1`  (save it as script5.nf).

```{bash} 

process MAP {
    
  container 'biocontainers/bwa:v0.7.17_cv1'
  tag "$sampleid" // same approach works

  input:
  tuple val(sampleid),path(infiles) // same approach works
  path transcriptome

  output:
  path '*' 
  publishDir "${params.outdir}/mapped" // we create a subdirectory to keep it cleaner 

  
  script:
  """
  bwa index ${transcriptome} 
  bwa mem ${transcriptome} ${infiles[0]} ${infiles[1]} -o ${sampleid}.sam
  """
}


workflow {

  // parse input:
  infile_channel = Channel.fromFilePairs( params.infile )
                    .view()
  // run FASTQC:
  FASTQC(infile_channel) 
  trimmed_channel = TRIM(infile_channel)
  FASTQC_SINGLE(trimmed_channel.trimmed)
  MAP(trimmed_channel.tup, params.transcriptome)
}

```

:::

BUT! It needs to be run with a full path!  
so: 

```{bash}
rp=`realpath ../../data/transcriptome.fa`
nextflow run ../code/script3.nf  -c ../code/config.nf -resume --infile "../../data/*{1,2}.fq" --outdir res --transcriptome $rp
```

